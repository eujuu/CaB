{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0902 18:56:29.434331  5056 deprecation_wrapper.py:119] From C:\\Users\\IVPL-D11\\models\\research\\object_detection\\utils\\label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pykinect2 import PyKinectV2\n",
    "from pykinect2.PyKinectV2 import *\n",
    "from pykinect2 import PyKinectRuntime\n",
    "from acquisitionKinect import AcquisitionKinect\n",
    "from frame import Frame as Frame\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ctypes\n",
    "import _ctypes\n",
    "import sys\n",
    "import face_recognition\n",
    "import os\n",
    "from scipy import io\n",
    "import math\n",
    "from gtts import gTTS\n",
    "import pyttsx3\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob import TextBlob\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 145)     # setting up new voice rate\n",
    "engine.setProperty('volume',1.0)    # setting up volume level  between 0 and 1\n",
    "voices = engine.getProperty('voices')       #getting details of current voice\n",
    "engine.setProperty('voice', voices[0].id)  #changing index, changes voices.\n",
    "\n",
    "#Load Basic Setting for Kinect\n",
    "Kinect = AcquisitionKinect()\n",
    "frame = Frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingforAction():\n",
    "    filename = 'KARDCADwithDrink3.mat'\n",
    "    AM = io.loadmat(filename, mat_dtype = False)\n",
    "\n",
    "    CiM_o = AM['Cim_out']\n",
    "\n",
    "    CiM = np.array([])\n",
    "    for i in range(25):\n",
    "        CiM = np.concatenate((CiM,np.array(CiM_o)['value'][0,0][0][int(i)][0]))\n",
    "    CiM = CiM.reshape((25, D))\n",
    "\n",
    "    iMaxis_o = AM['IMaxis_out']\n",
    "    iMaxis = np.array([])\n",
    "    for i in range(3):\n",
    "        iMaxis = np.concatenate((iMaxis,np.array(iMaxis_o)['value'][0,0][0][int(i)][0]))\n",
    "    iMaxis = iMaxis.reshape((3, D))\n",
    "    \n",
    "    iMjoints_o = AM['IMjoints_out']\n",
    "    iMjoints = np.array([])\n",
    "    for i in range(14):\n",
    "        iMjoints = np.concatenate((iMjoints,np.array(iMjoints_o)['value'][0,0][0][int(i)][0]))\n",
    "    iMjoints = iMjoints.reshape((14, D))\n",
    "    \n",
    "    AM_o = AM['AM2str']\n",
    "    AMM = np.array([])\n",
    "    for i in range(4):\n",
    "        AMM = np.concatenate((AMM,np.array(AM_o)['value'][0,0][0][int(i)][0]))\n",
    "    AMM = AMM.reshape((4, D))\n",
    "    \n",
    "    return CiM, iMaxis, iMjoints, AMM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosAngle (u, v):\n",
    "    cosAngle = np.dot(u,v)/(np.linalg.norm(u)*np.linalg.norm(v))\n",
    "    return cosAngle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizeHV (v):\n",
    "    threshold = 0\n",
    "    for i in range(len(v)):\n",
    "        if v[i] > threshold:\n",
    "            v[i] = 1\n",
    "        else:\n",
    "            v[i] = -1\n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(data, bins):\n",
    "    split = np.array_split(np.sort(data), bins)\n",
    "    cutoffs = [x[-1] for x in split]\n",
    "    cutoffs = cutoffs[:-1]\n",
    "    discrete = np.digitize(data, cutoffs, right=True)\n",
    "    return discrete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdcResult(AM,M0,CiM,iMjoints,iMaxis,MAXL,compareAngle):\n",
    "    #TP = np.zeros((1,17))\n",
    "    #FN = np.zeros((1,17))\n",
    "    #FP = np.zeros((1,17))\n",
    "    predictedLabel = -1\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    print(\"in\")\n",
    "    #for j in range (3):\n",
    "    for i in range(1, 5):\n",
    "        if(i == 1 or i == 2 or i==3 or i == 4 ):\n",
    "            tmp = np.zeros(D)\n",
    "            M = discretize(M0, MAXL)\n",
    "            M = M.reshape((30, 42))\n",
    "            for k in range( len(M)):\n",
    "                    \n",
    "                for n in range(len(M[0])):\n",
    "                       \n",
    "                    jointHDC = iMjoints[math.floor(n/3)]\n",
    "                    axisHDC = iMaxis[n%3]\n",
    "                     \n",
    "                    valueHDC = CiM[M[k][n]]\n",
    "                       #\n",
    "                    tmp += ((jointHDC*axisHDC) * valueHDC)\n",
    "                maxAngle = compareAngle\n",
    "                for b in range (1,5):\n",
    "                        \n",
    "                    if(b == 1 or b == 2 or b==3 or b ==4 ):\n",
    "                        angle = cosAngle (AM[b-1], binarizeHV(tmp))\n",
    "                            \n",
    "                        if (angle > maxAngle):\n",
    "                            maxAngle = angle\n",
    "                            predictedLabel = b\n",
    "                    #if predictedLabel == i:\n",
    "                        #TP(:,i) = TP(:,i)+1\n",
    "                    #else:\n",
    "                        #FN(:,i) = FN(:,i)+1;\n",
    "                        #FP(:,predictedLabel) = FP(:,predictedLabel)+1\n",
    "   #print(\"predictLabel:\", predictedLabel)\n",
    "\n",
    "    #precision = TP./(TP+FP)\n",
    "    #recall = TP./(TP+FN)\n",
    "    return predictedLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# setting for Face Recognition\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "# Load sample pictures and learn how to recognize it.\n",
    "dirname = 'face_reco/knowns'\n",
    "files = os.listdir(dirname)\n",
    "for filename in files:\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    if ext == '.jpg':\n",
    "        known_face_names.append(name)\n",
    "        pathname = os.path.join(dirname, filename)\n",
    "        img = face_recognition.load_image_file(pathname)\n",
    "        face_encoding = face_recognition.face_encodings(img)[0]\n",
    "        known_face_encodings.append(face_encoding)\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['person', 165.12396694214877], ['couch', 172.98347107438016]]\n",
      "face:  []\n",
      "people:  []\n",
      "people_max:  -1\n",
      "index:  0\n",
      "detected object: \n",
      " [['person', 165.12396694214877], ['couch', 172.98347107438016]]\n",
      "find 0\n",
      "[['person', 168.73553719008265]]\n",
      "find 1\n",
      "[['person', 166.8595041322314]]\n",
      "find 2\n",
      "[['person', 167.69421487603304]]\n",
      "find 3\n",
      "[['person', 168.13223140495867]]\n",
      "find 4\n",
      "[['person', 168.2396694214876]]\n",
      "find 5\n",
      "[['person', 168.47107438016528]]\n",
      "find 6\n",
      "[['person', 167.87603305785123]]\n",
      "find 7\n",
      "[['Unknown person', 167.69421487603304]]\n",
      "face:  ['Unknown person']\n",
      "people:  ['Unknown person']\n",
      "people_max:  0\n",
      "find 8\n",
      "[['Unknown person', 167.70247933884298]]\n",
      "find 9\n",
      "[['Unknown person', 168.40495867768595]]\n",
      "find 10\n",
      "[['Unknown person', 166.54545454545453]]\n",
      "find 11\n",
      "[['Unknown person', 168.89256198347107]]\n",
      "find 12\n",
      "[['Unknown person', 167.1487603305785]]\n",
      "find 13\n",
      "[['Unknown person', 169.30578512396696]]\n",
      "find 14\n",
      "[['Unknown person', 166.25619834710744]]\n",
      "find 15\n",
      "[['Unknown person', 167.61157024793388]]\n",
      "find 16\n",
      "[['Unknown person', 166.47107438016528]]\n",
      "find 17\n",
      "[['person', 168.34710743801654]]\n",
      "find 18\n",
      "[['person', 168.48760330578511]]\n",
      "find 19\n",
      "[['person', 168.1818181818182]]\n",
      "find 20\n",
      "[['person', 167.56198347107437]]\n",
      "find 21\n",
      "[['person', 168.5206611570248]]\n",
      "find 22\n",
      "[['person', 166.87603305785123]]\n",
      "find 23\n",
      "[['person', 168.19834710743802]]\n",
      "find 24\n",
      "[['person', 168.17355371900825]]\n",
      "find 25\n",
      "[['Unknown person', 167.77685950413223]]\n",
      "find 26\n",
      "[['Unknown person', 168.04132231404958]]\n",
      "find 27\n",
      "[['Unknown person', 166.8512396694215]]\n",
      "find 28\n",
      "[['Unknown person', 166.55371900826447]]\n",
      "find 29\n",
      "in\n",
      "Action Detect----------------------------------------------------------\n",
      "sit\n",
      "-----------------------------------------------------------------------\n",
      "eng:  Unknown person is sitting in front of couch.\n",
      "ko:  알 수없는 사람이 소파 앞에 앉아있다.\n",
      "[['Unknown person', 162.35537190082644]]\n",
      "face:  ['Unknown person']\n",
      "people:  ['Unknown person']\n",
      "people_max:  -1\n",
      "index:  0\n",
      "detected object: \n",
      " [['Unknown person', 162.35537190082644]]\n",
      "find 0\n",
      "[['Unknown person', 164.77685950413223]]\n",
      "find 1\n",
      "[['Unknown person', 167.37190082644628]]\n",
      "find 2\n",
      "[['Unknown person', 166.44628099173553]]\n",
      "find 3\n",
      "[['Unknown person', 100.08264462809917], ['Unknown person', 165.9090909090909]]\n",
      "face:  ['Unknown person', 'Unknown person']\n",
      "people:  ['Unknown person']\n",
      "people_max:  1\n",
      "index:  1\n",
      "detected object: \n",
      " [['Unknown person', 100.08264462809917], ['Unknown person', 165.9090909090909]]\n",
      "find 4\n",
      "[['Unknown person', 169.94214876033058], ['couch', 185.88429752066116]]\n",
      "face:  ['Unknown person', 'Unknown person']\n",
      "people:  ['Unknown person']\n",
      "people_max:  1\n",
      "find 5\n",
      "[['Unknown person', 129.87603305785123], ['person', 166.9090909090909], ['couch', 175.92561983471074]]\n",
      "index:  1\n",
      "detected object: \n",
      " [['Unknown person', 129.87603305785123], ['person', 166.9090909090909], ['couch', 175.92561983471074]]\n",
      "find 6\n",
      "[['person', 172.27272727272728], ['Unknown person', 224.45454545454547]]\n",
      "find 7\n",
      "[['person', 176.1818181818182], ['person', 223.86776859504133]]\n",
      "find 8\n",
      "[['person', 80.1900826446281]]\n",
      "find 9\n",
      "[['person', 89.26446280991736]]\n",
      "find 10\n",
      "[['person', 84.45454545454545]]\n",
      "find 11\n",
      "[['person', 166.65289256198346], ['person', 241.38842975206612]]\n",
      "find 12\n",
      "[['person', 76.72727272727273], ['couch', 173.51239669421489]]\n",
      "find 13\n",
      "[]\n",
      "find 14\n",
      "[['person', 74.07438016528926], ['person', 165.59504132231405]]\n",
      "find 15\n",
      "[['person', 67.43801652892562], ['Unknown person', 169.0]]\n",
      "find 16\n",
      "[['person', 56.48760330578512], ['Unknown person', 168.8181818181818], ['couch', 181.28099173553719]]\n",
      "find 17\n",
      "[['Unknown person', 166.02479338842974]]\n",
      "find 18\n",
      "[['Unknown person', 164.96694214876032]]\n",
      "find 19\n",
      "[['Unknown person', 169.36363636363637]]\n",
      "find 20\n",
      "[['Unknown person', 167.8181818181818]]\n",
      "find 21\n",
      "[['Unknown person', 167.98347107438016]]\n",
      "find 22\n",
      "[['Unknown person', 167.1404958677686]]\n",
      "find 23\n",
      "[['Unknown person', 167.97520661157026]]\n",
      "find 24\n",
      "[['Unknown person', 168.20661157024793]]\n",
      "find 25\n",
      "[['Unknown person', 167.82644628099175]]\n",
      "find 26\n",
      "[['Unknown person', 167.46280991735537]]\n",
      "find 27\n",
      "[['Unknown person', 168.23140495867767]]\n",
      "find 28\n",
      "[['Unknown person', 167.48760330578511]]\n",
      "find 29\n",
      "in\n",
      "Action Detect----------------------------------------------------------\n",
      "drink\n",
      "-----------------------------------------------------------------------\n",
      "eng:  Unknown person is drinking water behind Unknown person and in front of couch.\n",
      "ko:  알 수없는 사람은 식수를 알 수없는 사람 뒤에 있고 소파 앞에 있습니다.\n",
      "[['person', 163.20661157024793], ['couch', 173.98347107438016]]\n",
      "face:  []\n",
      "people:  []\n",
      "people_max:  -1\n",
      "index:  0\n",
      "detected object: \n",
      " [['person', 163.20661157024793], ['couch', 173.98347107438016]]\n",
      "find 0\n",
      "[['person', 163.92561983471074], ['couch', 171.6694214876033]]\n",
      "find 1\n",
      "[['Unknown person', 162.04132231404958], ['couch', 176.21487603305786]]\n",
      "face:  ['Unknown person']\n",
      "people:  ['Unknown person']\n",
      "people_max:  0\n",
      "find 2\n",
      "[['Unknown person', 162.40495867768595], ['couch', 181.6694214876033]]\n",
      "find 3\n",
      "[['Unknown person', 162.67768595041323], ['couch', 177.20661157024793]]\n",
      "find 4\n",
      "[['Unknown person', 162.88429752066116], ['couch', 172.05785123966942]]\n",
      "find 5\n",
      "[['Unknown person', 162.55371900826447], ['couch', 173.3388429752066]]\n",
      "find 6\n",
      "[['Unknown person', 161.8181818181818], ['couch', 177.87603305785123]]\n",
      "find 7\n",
      "[['Unknown person', 162.20661157024793], ['couch', 175.05785123966942]]\n",
      "find 8\n",
      "[['Unknown person', 162.53719008264463], ['couch', 177.74380165289256]]\n",
      "find 9\n",
      "[['Unknown person', 162.08264462809916], ['couch', 172.49586776859505]]\n",
      "find 10\n",
      "[['Unknown person', 162.9090909090909], ['couch', 174.9917355371901]]\n",
      "find 11\n",
      "[['Unknown person', 163.28099173553719], ['couch', 173.7603305785124]]\n",
      "find 12\n",
      "[['Unknown person', 162.3305785123967], ['couch', 174.65289256198346]]\n",
      "find 13\n",
      "[['Unknown person', 161.97520661157026], ['couch', 172.83471074380165]]\n",
      "find 14\n",
      "[['Unknown person', 162.35537190082644], ['couch', 174.35537190082644]]\n",
      "find 15\n",
      "[['Unknown person', 163.06611570247935], ['couch', 174.3305785123967]]\n",
      "find 16\n",
      "[['Unknown person', 161.83471074380165], ['couch', 178.7603305785124]]\n",
      "find 17\n",
      "[['Unknown person', 161.5206611570248], ['couch', 178.74380165289256]]\n",
      "find 18\n",
      "[['Unknown person', 161.900826446281], ['couch', 179.23140495867767]]\n",
      "find 19\n",
      "[['Unknown person', 162.2479338842975], ['couch', 172.89256198347107]]\n",
      "find 20\n",
      "[['Unknown person', 162.03305785123968], ['couch', 171.4214876033058]]\n",
      "find 21\n",
      "[['Unknown person', 162.10743801652893], ['couch', 177.07438016528926]]\n",
      "find 22\n",
      "[['Unknown person', 162.1404958677686], ['couch', 179.67768595041323]]\n",
      "find 23\n",
      "[['Unknown person', 161.84297520661158], ['couch', 174.3801652892562]]\n",
      "find 24\n",
      "[['Unknown person', 162.0], ['couch', 176.80165289256198]]\n",
      "find 25\n",
      "[['Unknown person', 162.4793388429752], ['couch', 177.89256198347107]]\n",
      "find 26\n",
      "[['Unknown person', 162.32231404958677], ['couch', 176.95867768595042]]\n",
      "find 27\n",
      "[['Unknown person', 162.49586776859505], ['couch', 171.92561983471074]]\n",
      "find 28\n",
      "[['Unknown person', 161.89256198347107], ['couch', 175.30578512396696]]\n",
      "find 29\n",
      "in\n",
      "Action Detect----------------------------------------------------------\n",
      "sit\n",
      "-----------------------------------------------------------------------\n",
      "eng:  Unknown person is sitting in front of couch.\n",
      "ko:  알 수없는 사람이 소파 앞에 앉아있다.\n",
      "[['person', 164.53719008264463], ['couch', 173.71074380165288]]\n",
      "face:  []\n",
      "people:  []\n",
      "people_max:  -1\n",
      "index:  0\n",
      "detected object: \n",
      " [['person', 164.53719008264463], ['couch', 173.71074380165288]]\n",
      "find 0\n",
      "[['person', 164.22314049586777], ['couch', 177.48760330578511]]\n",
      "find 1\n",
      "[['person', 164.29752066115702], ['couch', 182.96694214876032]]\n",
      "find 2\n",
      "[['person', 164.19834710743802], ['couch', 175.08264462809916]]\n",
      "find 3\n",
      "[['person', 164.17355371900825], ['couch', 176.0909090909091]]\n",
      "find 4\n",
      "[['person', 163.77685950413223], ['couch', 176.59504132231405]]\n",
      "find 5\n",
      "[['person', 163.08264462809916], ['couch', 176.0909090909091]]\n",
      "find 6\n",
      "[['person', 163.56198347107437], ['couch', 172.22314049586777]]\n",
      "find 7\n",
      "[['person', 163.58677685950414], ['couch', 174.9504132231405]]\n",
      "find 8\n",
      "[['person', 163.68595041322314], ['couch', 180.19834710743802]]\n",
      "find 9\n",
      "[['person', 163.9090909090909], ['couch', 179.69421487603304]]\n",
      "find 10\n",
      "[['person', 163.099173553719], ['couch', 175.27272727272728]]\n",
      "find 11\n",
      "[['person', 163.37190082644628], ['couch', 176.8512396694215]]\n",
      "find 12\n",
      "[['person', 164.30578512396696], ['couch', 176.38842975206612]]\n",
      "find 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Unknown person', 151.0082644628099]]\n",
      "face:  ['Unknown person']\n",
      "people:  ['Unknown person']\n",
      "people_max:  0\n",
      "find 14\n",
      "[['Unknown person', 146.3388429752066]]\n",
      "find 15\n",
      "[['Unknown person', 126.6694214876033], ['couch', 181.22314049586777]]\n",
      "find 16\n",
      "[['Unknown person', 112.79338842975207]]\n",
      "find 17\n",
      "[['couch', 117.91735537190083]]\n",
      "find 18\n",
      "[['Unknown person', 94.04132231404958]]\n",
      "find 19\n",
      "[['Unknown person', 86.39669421487604]]\n",
      "find 20\n",
      "[['Unknown person', 50.54545454545455]]\n",
      "find 21\n",
      "[['person', 42.3801652892562]]\n",
      "find 22\n",
      "[['person', 24.884297520661157]]\n",
      "find 23\n",
      "[['person', 19.0]]\n",
      "find 24\n",
      "[['person', 27.0]]\n",
      "find 25\n",
      "[['person', 40.96694214876033]]\n",
      "find 26\n",
      "[]\n",
      "find 27\n",
      "[]\n",
      "find 28\n",
      "[]\n",
      "find 29\n",
      "in\n",
      "Action Detect----------------------------------------------------------\n",
      "sit\n",
      "-----------------------------------------------------------------------\n",
      "eng:  Unknown person is sitting in front of couch.\n",
      "ko:  알 수없는 사람이 소파 앞에 앉아있다.\n",
      "[['person', 18.768595041322314]]\n",
      "face:  []\n",
      "people:  []\n",
      "people_max:  -1\n",
      "index:  0\n",
      "detected object: \n",
      " [['person', 18.768595041322314]]\n",
      "find 0\n",
      "[['person', 26.628099173553718]]\n",
      "find 1\n",
      "[['person', 26.43801652892562]]\n",
      "find 2\n",
      "[['person', 28.429752066115704]]\n",
      "find 3\n",
      "[['person', 26.801652892561982]]\n",
      "find 4\n",
      "[['person', 24.760330578512395]]\n",
      "find 5\n",
      "[['person', 24.75206611570248]]\n",
      "find 6\n",
      "[['person', 22.074380165289256], ['chair', 172.96694214876032]]\n",
      "index:  0\n",
      "detected object: \n",
      " [['person', 22.074380165289256], ['chair', 172.96694214876032]]\n",
      "find 7\n",
      "[['person', 23.31404958677686]]\n",
      "find 8\n",
      "[['person', 26.93388429752066], ['chair', 184.9917355371901]]\n",
      "find 9\n",
      "[['person', 194.0]]\n",
      "find 10\n",
      "[['person', 194.0]]\n",
      "find 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-2ed9b099bfd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcategory_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0muse_normalized_coordinates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             line_thickness=8)\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\models\\research\\object_detection\\utils\\visualization_utils.py\u001b[0m in \u001b[0;36mvisualize_boxes_and_labels_on_image_array\u001b[1;34m(image, boxes, classes, scores, category_index, instance_masks, instance_boundaries, keypoints, use_normalized_coordinates, max_boxes_to_draw, min_score_thresh, agnostic_mode, line_thickness, groundtruth_box_visualization_color, skip_scores, skip_labels)\u001b[0m\n\u001b[0;32m    806\u001b[0m         \u001b[0mthickness\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_thickness\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[0mdisplay_str_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbox_to_display_str_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m         use_normalized_coordinates=use_normalized_coordinates)\n\u001b[0m\u001b[0;32m    809\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkeypoints\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         draw_keypoints_on_image_array(\n",
      "\u001b[1;32m~\\models\\research\\object_detection\\utils\\visualization_utils.py\u001b[0m in \u001b[0;36mdraw_bounding_box_on_image_array\u001b[1;34m(image, ymin, xmin, ymax, xmax, color, thickness, display_str_list, use_normalized_coordinates)\u001b[0m\n\u001b[0;32m    123\u001b[0m       \u001b[0mcoordinates\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mabsolute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \"\"\"\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0mimage_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m   draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n\u001b[0;32m    127\u001b[0m                              \u001b[0mthickness\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_str_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2670\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2611\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2613\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2543\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2545\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2546\u001b[0m     \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2547\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mnew\u001b[1;34m(mode, size, color)\u001b[0m\n\u001b[0;32m   2507\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2508\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2509\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def make_sentence(depth, position, index, start, end):\n",
    "    objects = \"\"\n",
    "    objects += position + \" \"\n",
    "    for i in range(start, end):\n",
    "        objects += depth[i][0] + \" and \"\n",
    "\n",
    "                                    \n",
    "    objects += depth[end][0]\n",
    "\n",
    "    return objects\n",
    "\n",
    "\n",
    "# Functions for Action Recognition\n",
    "D = 7000\n",
    "numActivities = 3\n",
    "MAXL = 25\n",
    "compareAngle = 0.5\n",
    "feature = np.zeros((20,3))\n",
    "people = []\n",
    "i = 1\n",
    "framecheck = 0\n",
    "max_depth = -1 \n",
    "max_people = -1\n",
    "frameset = np.array([])\n",
    "norm_frameset = np.array([])\n",
    "CiM, iMaxis, iMjoints, AMM = loadingforAction()\n",
    "flag = 0\n",
    "index = -1\n",
    "framecheck = 0\n",
    "#Object Detection\n",
    "with detection_graph.as_default():\n",
    "  with tf.Session(graph=detection_graph) as sess:\n",
    "    while True:\n",
    "        peop = 0\n",
    "        situation=\"\"\n",
    "        # --- Getting frames and drawing\n",
    "        Kinect.get_frame(frame)\n",
    "        Kinect.get_color_frame()\n",
    "        image_np = Kinect._kinect.get_last_color_frame()\n",
    "        #image_np = Kinect._frameRGB\n",
    "        image_depth = Kinect._frameDepthQuantized \n",
    "        Skeleton_img = Kinect._frameSkeleton\n",
    "        image_np = np.reshape(image_np, (Kinect._kinect.color_frame_desc.Height, Kinect._kinect.color_frame_desc.Width, 4))\n",
    "        image_np = cv2.cvtColor(image_np, cv2.COLOR_RGBA2RGB)\n",
    "        show_img = image_np\n",
    "       # show_img = image_np[ 200:1020, 350:1780]\n",
    "        show_img = cv2.resize(show_img, (512,424))\n",
    "        \n",
    "        #image_np = cv2.cvtColor(image_np, cv2.COLOR_RGBA2RGB)\n",
    "        #image_np = image_np[ 200:1020, 350:1780]\n",
    "        #image_np = cv2.resize(image_np, (512,424))\n",
    "        rgb_small_frame = cv2.resize(image_np, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "# Face recognition\n",
    "        if process_this_frame:\n",
    "            # Find all the faces and face encodings in the current frame of video\n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "            face_names = []\n",
    "            for face_encoding in face_encodings:\n",
    "                distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                min_value = min(distances)\n",
    "\n",
    "\n",
    "                name = \"Unknown person\"\n",
    "                if min_value < 0.3:\n",
    "                    index = np.argmin(distances)\n",
    "                    name = known_face_names[index]\n",
    "\n",
    "                face_names.append(name)\n",
    "\n",
    "        process_this_frame = not process_this_frame\n",
    "\n",
    "       \n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(image_np, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            # Draw a label with a name below the face\n",
    "            cv2.rectangle(image_np, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            \n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(image_np, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "            \n",
    "#---------------- Object Detection\n",
    "\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    " \n",
    "        (boxes, scores, classes, num) = sess.run(\n",
    "            [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "            feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np,\n",
    "            np.squeeze(boxes),\n",
    "            np.squeeze(classes).astype(np.int32),\n",
    "            np.squeeze(scores),\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=8)\n",
    "\n",
    "\n",
    "        coordinates = vis_util.return_coordinates(\n",
    "                    image_np,\n",
    "                    np.squeeze(boxes),\n",
    "                    np.squeeze(classes).astype(np.int32),\n",
    "                    np.squeeze(scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=8,\n",
    "                    min_score_thresh=0.5)\n",
    "        \n",
    "        if coordinates is not None:\n",
    "            depth_arr = [[0 for x in range(2)] for y in range(len(coordinates))]\n",
    "            real_depth_arr = [[0 for x in range(2)] for y in range(len(coordinates))]\n",
    "            count = 0\n",
    "            for i in range(len(coordinates)):\n",
    "                if coordinates[i][0] == 'person':\n",
    "                    flag = 1\n",
    "                    if count < len(face_names):\n",
    "                        coordinates[i][0] = face_names[count]\n",
    "                        count += 1\n",
    "                        \n",
    "            #print(coordinates)\n",
    "            xpoint_for_depth=[]\n",
    "            ypoint_for_depth=[]\n",
    "            \n",
    "            #print(\"object 개수:\", len(coordinates))\n",
    "            for i in range(len(coordinates)):\n",
    "                ypoint_for_depth.append(int((coordinates[i][1]+coordinates[i][2])/2))\n",
    "                xpoint_for_depth.append(int((coordinates[i][3]+coordinates[i][4])/2))\n",
    "\n",
    "            #print(\"ypoint_for_depth:\", ypoint_for_depth)\n",
    "            #print(\"xpoint_for_depth:\", xpoint_for_depth)\n",
    "            m = 0\n",
    "            for i in range(len(coordinates)):\n",
    "                if(coordinates[i][0]!=\"N/A\" and coordinates[i][0] not in depth_arr):\n",
    "                    depth_arr[m][0] = coordinates[i][0]\n",
    "                    depth_arr[m][1] = 0\n",
    "                    for x in range (-5, 6):\n",
    "                        for y in range(-5, 6):\n",
    "                            depth_arr[m][1] += image_depth[int((ypoint_for_depth[i]+x) * 424 / 1080)][int((xpoint_for_depth[i]+y) * 512 / 1920)]\n",
    "                            show_img[int((ypoint_for_depth[i]+x) * 424 / 1080)][int((xpoint_for_depth[i]+y) * 512 / 1920)] = [255, 0,95]\n",
    "                    depth_arr[m][1] /= 121\n",
    "                    m+=1\n",
    "\n",
    "            # Compare each objects' depth. (Sorting: close -> far)\n",
    "            depth_arr.sort(key=lambda x:x[1])\n",
    "            print(depth_arr)\n",
    "       \n",
    "               # print(coordinates[i][0], \"'s depth: \", Pixel_Depth)\n",
    "        image_np = cv2.resize(image_np,  (640, 480))\n",
    "        cv2.imshow(\"ee\", image_np)  \n",
    "        \n",
    "        cv2.imshow(\"depthh\", image_depth)\n",
    "        #cv2.imshow('KINECT Color', image_np)\n",
    "        \n",
    "        # Rule of Generating Sentence\n",
    "        if(len(face_names)> max_people):\n",
    "            print(\"face: \", face_names)\n",
    "            for i in range(len(face_names)): \n",
    "                if face_names[i] not in people:\n",
    "                    people.append( face_names[i])\n",
    "            print(\"people: \", people)\n",
    "            print(\"people_max: \", max_people)\n",
    "            max_people = len(people)\n",
    "            \n",
    "        if(len(depth_arr)> max_depth):\n",
    "            tmp_situation = \"\"\n",
    "            for i in range(len(depth_arr)):\n",
    "                if(depth_arr[i][0] in face_names or depth_arr[i][0]== \"person\"):\n",
    "                    index = i\n",
    "            print(\"index: \", index)\n",
    "\n",
    "            print(\"detected object: \\n\", depth_arr)                        \n",
    "            if index==0:\n",
    "                tmp_situation += make_sentence(depth_arr, \"in front of\", index, 1, len(depth_arr)-1 )\n",
    "            elif index == len(depth_arr)-1:\n",
    "                tmp_situation += make_sentence(depth_arr, \"behind\", index, 0, len(depth_arr)-2)\n",
    "            elif index > 0 and index <len(depth_arr)-1 :\n",
    "                tmp_situation += make_sentence(depth_arr, \"behind\", index, 0, index-1 )\n",
    "                tmp_situation += \" and \"\n",
    "                tmp_situation += make_sentence(depth_arr, \"in front of\", index, index + 1, len(depth_arr)-1 )\n",
    "            max_depth = len(depth_arr)\n",
    "#Action Recognition\n",
    "       \n",
    "        \n",
    "        if Skeleton_img is not None:\n",
    "\n",
    "            \n",
    "            cv2.resize(Skeleton_img, (960, 540))\n",
    "            cv2.imshow(\"joint\", Skeleton_img)\n",
    "            print(\"find\", framecheck)            \n",
    "           \n",
    "            feature[1][0] = Kinect.joint_points3D[3].x\n",
    "            feature[1][1] = Kinect.joint_points3D[3].y\n",
    "            feature[1][2] = Kinect.joint_points3D[3].z\n",
    "            \n",
    "            feature[2][0] = Kinect.joint_points3D[2].x\n",
    "            feature[2][1] = Kinect.joint_points3D[2].y\n",
    "            feature[2][2] = Kinect.joint_points3D[2].z\n",
    "            \n",
    "            feature[3][0] = Kinect.joint_points3D[8].x\n",
    "            feature[3][1] = Kinect.joint_points3D[8].y\n",
    "            feature[3][2] = Kinect.joint_points3D[8].z\n",
    "\n",
    "            feature[4][0] = Kinect.joint_points3D[9].x\n",
    "            feature[4][1] = Kinect.joint_points3D[9].y\n",
    "            feature[4][2] = Kinect.joint_points3D[9].z\n",
    "\n",
    "            feature[5][0] = Kinect.joint_points3D[11].x\n",
    "            feature[5][1] = Kinect.joint_points3D[11].y\n",
    "            feature[5][2] = Kinect.joint_points3D[11].z\n",
    "\n",
    "            feature[6][0] = Kinect.joint_points3D[4].x\n",
    "            feature[6][1] = Kinect.joint_points3D[4].y\n",
    "            feature[6][2] = Kinect.joint_points3D[4].z\n",
    "\n",
    "            feature[7][0] = Kinect.joint_points3D[5].x\n",
    "            feature[7][1] = Kinect.joint_points3D[5].y\n",
    "            feature[7][2] = Kinect.joint_points3D[5].z\n",
    "\n",
    "            feature[8][0] = Kinect.joint_points3D[7].x\n",
    "            feature[8][1] = Kinect.joint_points3D[7].y\n",
    "            feature[8][2] = Kinect.joint_points3D[7].z\n",
    "\n",
    "            feature[9][0] = Kinect.joint_points3D[1].x\n",
    "            feature[9][1] = Kinect.joint_points3D[1].y\n",
    "            feature[9][2] = Kinect.joint_points3D[1].z\n",
    "\n",
    "            feature[10][0] = Kinect.joint_points3D[16].x\n",
    "            feature[10][1] = Kinect.joint_points3D[16].y\n",
    "            feature[10][2] = Kinect.joint_points3D[16].z\n",
    "\n",
    "            feature[11][0] = Kinect.joint_points3D[17].x\n",
    "            feature[11][1] = Kinect.joint_points3D[17].y\n",
    "            feature[11][2] = Kinect.joint_points3D[17].z\n",
    "\n",
    "            feature[12][0] = Kinect.joint_points3D[19].x\n",
    "            feature[12][1] = Kinect.joint_points3D[19].y\n",
    "            feature[12][2] = Kinect.joint_points3D[19].z\n",
    "\n",
    "            feature[13][0] = Kinect.joint_points3D[12].x\n",
    "            feature[13][1] = Kinect.joint_points3D[12].y\n",
    "            feature[13][2] = Kinect.joint_points3D[12].z\n",
    "\n",
    "            feature[14][0] = Kinect.joint_points3D[13].x\n",
    "            feature[14][1] = Kinect.joint_points3D[13].y\n",
    "            feature[14][2] = Kinect.joint_points3D[13].z\n",
    "\n",
    "            feature[15][0] = Kinect.joint_points3D[15].x\n",
    "            feature[15][1] = Kinect.joint_points3D[15].y\n",
    "            feature[15][2] = Kinect.joint_points3D[15].z\n",
    "            tmp = []\n",
    "            for i in range (1, 16):\n",
    "                for j in range(3):\n",
    "                    tmp.append(feature[i][j])\n",
    "\n",
    "            frameset = np.concatenate((frameset, tmp), axis = 0)\n",
    "            framecheck+=1\n",
    "            if(framecheck == 30):\n",
    "                frameset = frameset.reshape((framecheck, 45))\n",
    "                for row in range(len(frameset)):\n",
    "                    \n",
    "                    torsox = float(frameset[row][24])\n",
    "                    torsoy = float(frameset[row][25])\n",
    "                    torsoz = float(frameset[row][26])\n",
    "                    neckx = float(frameset[row][3])\n",
    "                    necky = float(frameset[row][4])\n",
    "                    neckz = float(frameset[row][5])\n",
    "                    denom = math.sqrt(math.pow((neckx - torsox),2) + math.pow((necky - torsoy),2) + math.pow((neckz - torsoz),2))\n",
    "                    tmp = []\n",
    "                    i = 0\n",
    "                    while (i < 24):\n",
    "                        tmp.append((float(frameset[row][i]) - torsox)/denom)\n",
    "                        tmp.append((float(frameset[row][i+1]) - torsoy)/denom)\n",
    "                        tmp.append((float(frameset[row][i+2]) - torsoz)/denom)\n",
    "                        i+=3\n",
    "                    i = 27\n",
    "                    while (i < 45):\n",
    "                        tmp.append((float(frameset[row][i]) - torsox)/denom)\n",
    "                        tmp.append((float(frameset[row][i+1]) - torsoy)/denom)\n",
    "                        tmp.append((float(frameset[row][i+2]) - torsoz)/denom)\n",
    "                        i+=3\n",
    "                    norm_frameset = np.concatenate((norm_frameset, tmp), axis = 0)\n",
    "                    \n",
    "                #norm_frameset = norm_frameset.reshape((k, 42))\n",
    "               # CiM,iMjoints,iMaxis = initItemMemories (D, MAXL)\n",
    "                \n",
    "                predictedLabel = hdcResult(AMM,norm_frameset,CiM,iMjoints,iMaxis,MAXL,compareAngle)\n",
    "                print(\"Action Detect----------------------------------------------------------\")\n",
    "                if(predictedLabel == 1):\n",
    "                    action = \"standing\"\n",
    "                    print(\"still\")\n",
    "                elif (predictedLabel == 2 ):\n",
    "                    action = \"sitting\"\n",
    "                    print (\"sit\")\n",
    "                elif (predictedLabel == 3 ):\n",
    "                    action = \"walking\"\n",
    "                    print (\"walk\")\n",
    "                elif predictedLabel == 4 :\n",
    "                    action = \"drinking water\"\n",
    "                    print(\"drink\")\n",
    "                print(\"-----------------------------------------------------------------------\")\n",
    "               \n",
    "                tmp = []\n",
    "                frameset = np.array([])\n",
    "                norm_frameset = np.array([])\n",
    "                framecheck = 0\n",
    "                \n",
    "                            \n",
    "       \n",
    "                back_objects = \"\"\n",
    "                front_objects = \"\"\n",
    "                if(flag==1):\n",
    "                    if(max_people <2): # one person\n",
    "                        if(max_people ==1):\n",
    "                            situation += people[0] + \" is \"\n",
    "                        elif max_people <1:\n",
    "                            situation += \"Unknown person is \"\n",
    "                        situation += action + \" \"\n",
    "                        situation += tmp_situation\n",
    "                        #back_objects += situation\n",
    "                        #front_objects += situation\n",
    "                        \n",
    "                        \n",
    "                    elif (max_people>=2) : # more than two people\n",
    "                        for i in range(len(people)-1):\n",
    "                            situation += people[i] + \" and \"\n",
    "                        situation += people[len(people)-1]+ \" are near by \"\n",
    "                   # if \"person\" in Pixel_Depth_Dict.keys():\n",
    "\n",
    "                        situation += action\n",
    "                    situation += \".\"\n",
    "                    print(\"eng: \", situation)\n",
    "                    word = TextBlob(situation)\n",
    "                    fin_situation = str(word.translate(from_lang='en', to='ko'))\n",
    "                    engine.say(fin_situation)\n",
    "                    engine.runAndWait()\n",
    "                    print(\"ko: \", fin_situation)\n",
    "                    max_depth = -1\n",
    "                    max_people = -1\n",
    "                    people = []\n",
    "                    #tts = gTTS(text=fin_situation, lang='ko')\n",
    "                    #tts.save(\"helloKO.mp3\")                    \n",
    "        i=i+1\n",
    "       # print(\"--------------------------------------------------- people: \", people)\n",
    "       # print(\"--------------------------------------------------- situation: \", situation)\n",
    "       # print(\"--------------------------------------------------- face: \", face_names)\n",
    "        \n",
    "                \n",
    "        \n",
    "\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
